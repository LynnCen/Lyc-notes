import{_ as i,c as a,o as t,a7 as n}from"./chunks/framework.BQb8NfN9.js";const E=JSON.parse('{"title":"K-Means 聚类算法","description":"","frontmatter":{},"headers":[],"relativePath":"ai/机器学习/08Kmeans.md","filePath":"ai/机器学习/08Kmeans.md","lastUpdated":1770642087000}'),l={name:"ai/机器学习/08Kmeans.md"};function e(h,s,p,r,k,d){return t(),a("div",null,s[0]||(s[0]=[n(`<h1 id="k-means-聚类算法" tabindex="-1">K-Means 聚类算法 <a class="header-anchor" href="#k-means-聚类算法" aria-label="Permalink to &quot;K-Means 聚类算法&quot;">​</a></h1><blockquote><p><strong>核心思想</strong>：根据样本间的相似性对样本进行分组，使同一簇内样本尽可能相似、不同簇间尽可能分离，从而发现数据内部结构与相互关系。</p></blockquote><hr><h2 id="一、数据探索与聚类概览" tabindex="-1">一、数据探索与聚类概览 <a class="header-anchor" href="#一、数据探索与聚类概览" aria-label="Permalink to &quot;一、数据探索与聚类概览&quot;">​</a></h2><h3 id="_1-使用-kmeans-进行数据探索聚类" tabindex="-1">1. 使用 KMeans 进行数据探索聚类 <a class="header-anchor" href="#_1-使用-kmeans-进行数据探索聚类" aria-label="Permalink to &quot;1. 使用 KMeans 进行数据探索聚类&quot;">​</a></h3><h4 id="_1-k-means-算法简介" tabindex="-1">（1）K-Means 算法简介 <a class="header-anchor" href="#_1-k-means-算法简介" aria-label="Permalink to &quot;（1）K-Means 算法简介&quot;">​</a></h4><table tabindex="0"><thead><tr><th>项目</th><th>说明</th></tr></thead><tbody><tr><td><strong>核心思想</strong></td><td>按样本相似性将样本集划分为 (k) 个簇，发现事物内部结构及相互关系</td></tr><tr><td><strong>关键参数</strong></td><td>需<strong>预先指定</strong>聚类数量 <code>n_clusters</code>（如 2/3/4），体现聚类的“自主设定”特性</td></tr><tr><td><strong>实际应用</strong></td><td>根据样本相似度探索数据结构，例如本案例数据可尝试 2/3/4 个簇并比较效果</td></tr></tbody></table><p>算法通过迭代更新簇中心（质心）和样本归属，最小化簇内距离和（或等价目标），属于<strong>无监督学习</strong>。</p><h4 id="_2-kmeans-模型构建流程概览" tabindex="-1">（2）KMeans 模型构建流程概览 <a class="header-anchor" href="#_2-kmeans-模型构建流程概览" aria-label="Permalink to &quot;（2）KMeans 模型构建流程概览&quot;">​</a></h4><ul><li><strong>模型效果</strong>：将原始数据按指定簇数聚类，本例中可对比 2 / 3 / 4 个簇的效果。</li><li><strong>数据准备</strong> → <strong>实例化并预测</strong> → <strong>展示聚类效果</strong> → <strong>评估与调参</strong>。</li></ul><hr><h3 id="_2-数据准备" tabindex="-1">2. 数据准备 <a class="header-anchor" href="#_2-数据准备" aria-label="Permalink to &quot;2. 数据准备&quot;">​</a></h3><table tabindex="0"><thead><tr><th>项目</th><th>说明</th></tr></thead><tbody><tr><td><strong>数据生成</strong></td><td>使用 <code>make_blobs</code> 生成 1000 个样本，每个样本 2 个特征</td></tr><tr><td><strong>质心位置</strong></td><td><code>centers=[[-1,-1],[0,0],[1,1],[2,2]]</code>，共 4 个簇中心</td></tr><tr><td><strong>离散程度</strong></td><td><code>cluster_std=[0.4, 0.2, 0.2, 0.2]</code>，控制各簇的散布程度</td></tr><tr><td><strong>可复现性</strong></td><td><code>random_state=22</code>（或 11）固定随机种子，便于复现</td></tr></tbody></table><p><strong>可视化要点</strong>：</p><ul><li>用 <code>plt.scatter(x[:,0], x[:,1])</code> 绘制散点：<code>x[:,0]</code> 为第一特征（横轴），<code>x[:,1]</code> 为第二特征（纵轴）。</li><li>特征矩阵 <code>x</code> 的<strong>列</strong>表示特征维度，本例为 2 维坐标。</li></ul><hr><h3 id="_3-实例化模型并预测" tabindex="-1">3. 实例化模型并预测 <a class="header-anchor" href="#_3-实例化模型并预测" aria-label="Permalink to &quot;3. 实例化模型并预测&quot;">​</a></h3><ul><li><strong>模型初始化</strong>： <ul><li><code>n_clusters</code>：聚类数量（如 2、3、4）。</li><li><code>init=&#39;k-means++&#39;</code>：优化质心初始化，减少陷入局部最优，默认会多次尝试选较优起点。</li><li><code>random_state</code>：固定随机性，保证结果一致。</li></ul></li><li><strong>训练与预测</strong>： <ul><li>使用 <strong><code>fit_predict(x)</code></strong> 一步完成训练和预测。</li><li>无监督学习<strong>不需要标签</strong>，直接对特征 <code>x</code> 操作，得到每个样本的簇标签 <code>y_pred</code>。</li></ul></li></ul><hr><h3 id="_4-展示聚类效果" tabindex="-1">4. 展示聚类效果 <a class="header-anchor" href="#_4-展示聚类效果" aria-label="Permalink to &quot;4. 展示聚类效果&quot;">​</a></h3><ul><li>结果可视化：<code>plt.scatter(x[:,0], x[:,1], c=y_pred)</code>，用 <code>c=y_pred</code> 按预测簇标号着色（0/1/2/3 对应不同颜色）。</li><li>评估聚类质量： <ul><li>使用 <strong>Calinski-Harabasz 指数</strong>（<code>calinski_harabasz_score(x, y_pred)</code>），<strong>分数越高</strong>通常表示簇间分离越好、簇内越紧凑，效果越好。</li><li>可对多个 <code>n_clusters</code> 取值分别聚类并计算该分数，选择较优的聚类数。</li></ul></li></ul><p><strong>注意</strong>：<code>cluster_std</code> 越大数据越分散；特征量纲差异大时建议先标准化；k-means++ 一般比随机初始化更稳定。</p><hr><h2 id="二、无监督聚类-k-means-实现" tabindex="-1">二、无监督聚类 K-Means 实现 <a class="header-anchor" href="#二、无监督聚类-k-means-实现" aria-label="Permalink to &quot;二、无监督聚类 K-Means 实现&quot;">​</a></h2><h3 id="_1-api-使用流程" tabindex="-1">1. API 使用流程 <a class="header-anchor" href="#_1-api-使用流程" aria-label="Permalink to &quot;1. API 使用流程&quot;">​</a></h3><ol><li><strong>数据准备</strong>：用 <code>make_blobs</code> 等生成或加载数据。</li><li><strong>模型构建</strong>：使用 <code>KMeans</code> 类实例化并设置 <code>n_clusters</code> 等参数。</li><li><strong>训练与预测</strong>：<code>fit_predict(x)</code> 得到聚类标签。</li><li><strong>效果评估</strong>：如采用 <code>calinski_harabasz_score</code> 评估，并配合可视化对比。</li></ol><hr><h3 id="_2-数据创建与展示" tabindex="-1">2. 数据创建与展示 <a class="header-anchor" href="#_2-数据创建与展示" aria-label="Permalink to &quot;2. 数据创建与展示&quot;">​</a></h3><p><strong>关键参数</strong>：</p><table tabindex="0"><thead><tr><th>参数</th><th>含义</th><th>示例</th></tr></thead><tbody><tr><td><code>n_samples</code></td><td>样本数</td><td>1000</td></tr><tr><td><code>n_features</code></td><td>特征数</td><td>2</td></tr><tr><td><code>centers</code></td><td>真实簇中心坐标</td><td><code>[[-1,-1],[0,0],[1,1],[2,2]]</code></td></tr><tr><td><code>cluster_std</code></td><td>各簇标准差</td><td><code>[0.4, 0.2, 0.2, 0.2]</code></td></tr></tbody></table><p><strong>可视化</strong>：<code>plt.figure()</code> 创建画布，<code>plt.scatter(x[:,0], x[:,1], marker=&#39;o&#39;)</code> 绘制散点图。</p><hr><h3 id="_3-数据生成示例代码" tabindex="-1">3. 数据生成示例代码 <a class="header-anchor" href="#_3-数据生成示例代码" aria-label="Permalink to &quot;3. 数据生成示例代码&quot;">​</a></h3><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> sklearn.datasets </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> make_blobs</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">x, y </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> make_blobs(</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    n_samples</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1000</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    n_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    centers</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[[</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], [</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], [</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], [</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]],</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    cluster_std</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.4</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">    random_state</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">11</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br></div></div><hr><h3 id="_4-模型实例化与预测" tabindex="-1">4. 模型实例化与预测 <a class="header-anchor" href="#_4-模型实例化与预测" aria-label="Permalink to &quot;4. 模型实例化与预测&quot;">​</a></h3><p><strong>核心参数</strong>：</p><table tabindex="0"><thead><tr><th>参数</th><th>含义</th><th>说明</th></tr></thead><tbody><tr><td><code>n_clusters</code></td><td>聚类数量</td><td>必须事先指定</td></tr><tr><td><code>init</code></td><td>质心初始化方式</td><td><code>&#39;k-means++&#39;</code> 优于随机</td></tr><tr><td><code>n_init</code></td><td>初始化尝试次数</td><td>1.4 版本后默认 <code>&#39;auto&#39;</code>，显式设置可避免警告</td></tr></tbody></table><p><strong>预测</strong>：<code>fit_predict(x)</code> 一次完成拟合与预测，返回每个样本的簇标签。</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> sklearn.cluster </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> KMeans</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">kmeans_cls </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> KMeans(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">n_clusters</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">init</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;k-means++&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">n_init</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;auto&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">y_pred </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> kmeans_cls.fit_predict(x)</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div><hr><h3 id="_5-模型评估与可视化" tabindex="-1">5. 模型评估与可视化 <a class="header-anchor" href="#_5-模型评估与可视化" aria-label="Permalink to &quot;5. 模型评估与可视化&quot;">​</a></h3><ul><li><strong>评估</strong>：<code>calinski_harabasz_score(x, y_pred)</code>，分数越高聚类效果越好。</li><li><strong>可视化</strong>：对比“原始数据分布”与“按 <code>y_pred</code> 着色的聚类结果”；可尝试不同 <code>n_clusters</code> 并比较。</li></ul><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> sklearn.metrics </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> calinski_harabasz_score</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(calinski_harabasz_score(x, y_pred))</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">plt.scatter(x[:, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], x[:, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">c</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">y_pred)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">plt.show()</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br></div></div><hr><h3 id="_6-参数调整实践" tabindex="-1">6. 参数调整实践 <a class="header-anchor" href="#_6-参数调整实践" aria-label="Permalink to &quot;6. 参数调整实践&quot;">​</a></h3><p><strong>典型实验</strong>（示例数据）：</p><table tabindex="0"><thead><tr><th>n_clusters</th><th>Calinski-Harabasz 分数</th><th>说明</th></tr></thead><tbody><tr><td>2</td><td>3125.94</td><td>簇数偏少</td></tr><tr><td>3</td><td>2964.31</td><td>略降</td></tr><tr><td>4</td><td><strong>5813.86</strong></td><td>本例最优，与真实 4 簇一致</td></tr></tbody></table><ul><li><strong>选择策略</strong>：比较不同 <code>n_clusters</code> 的 CH 分数；分数明显下降或拐点常对应较合理的簇数（需结合业务与可视化判断）。</li></ul><hr><h3 id="_7-完整代码结构" tabindex="-1">7. 完整代码结构 <a class="header-anchor" href="#_7-完整代码结构" aria-label="Permalink to &quot;7. 完整代码结构&quot;">​</a></h3><ol><li>导入依赖（<code>sklearn.cluster.KMeans</code>、<code>sklearn.datasets.make_blobs</code>、<code>matplotlib</code>、评估指标等）。</li><li>使用 <code>make_blobs</code> 创建测试数据。</li><li>可选：可视化原始数据分布。</li><li>实例化 <code>KMeans</code>，调用 <code>fit_predict(x)</code>。</li><li>可视化聚类结果（按 <code>y_pred</code> 着色）。</li><li>使用 CH 分数（及可选其他指标）评估效果。</li></ol><p><strong>示例框架</strong>：</p><div class="language-python vp-adaptive-theme line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">python</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> sklearn.cluster </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> KMeans</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> sklearn.datasets </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> make_blobs</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">from</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> sklearn.metrics </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> calinski_harabasz_score</span></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">import</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> matplotlib.pyplot </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">as</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> plt</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">def</span><span style="--shiki-light:#6F42C1;--shiki-dark:#B392F0;"> kmeans_demo</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">():</span></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 数据准备</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    x, y </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> make_blobs(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">n_samples</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1000</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">n_features</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">                      centers</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[[</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">,</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">]],</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">                      cluster_std</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">[</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.4</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0.2</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">],</span></span>
<span class="line"><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">                      random_state</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">11</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 原始数据可视化（可选）</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    plt.figure(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">figsize</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">6</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    plt.scatter(x[:, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], x[:, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">marker</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;o&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    plt.title(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;Original data&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    plt.show()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 模型训练与预测</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    kmeans </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> KMeans(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">n_clusters</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">init</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;k-means++&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">n_init</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&#39;auto&#39;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    y_pred </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> kmeans.fit_predict(x)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#6A737D;--shiki-dark:#6A737D;">    # 结果评估与可视化</span></span>
<span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">    print</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;CH Score:&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, calinski_harabasz_score(x, y_pred))</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    plt.figure(</span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">figsize</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">6</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">4</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">))</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    plt.scatter(x[:, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">0</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], x[:, </span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">1</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">], </span><span style="--shiki-light:#E36209;--shiki-dark:#FFAB70;">c</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">y_pred)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    plt.title(</span><span style="--shiki-light:#032F62;--shiki-dark:#9ECBFF;">&quot;K-Means clustering (k=4)&quot;</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">)</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">    plt.show()</span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br><span class="line-number">5</span><br><span class="line-number">6</span><br><span class="line-number">7</span><br><span class="line-number">8</span><br><span class="line-number">9</span><br><span class="line-number">10</span><br><span class="line-number">11</span><br><span class="line-number">12</span><br><span class="line-number">13</span><br><span class="line-number">14</span><br><span class="line-number">15</span><br><span class="line-number">16</span><br><span class="line-number">17</span><br><span class="line-number">18</span><br><span class="line-number">19</span><br><span class="line-number">20</span><br><span class="line-number">21</span><br><span class="line-number">22</span><br><span class="line-number">23</span><br><span class="line-number">24</span><br><span class="line-number">25</span><br><span class="line-number">26</span><br><span class="line-number">27</span><br><span class="line-number">28</span><br></div></div><hr><h3 id="_8-注意事项" tabindex="-1">8. 注意事项 <a class="header-anchor" href="#_8-注意事项" aria-label="Permalink to &quot;8. 注意事项&quot;">​</a></h3><table tabindex="0"><thead><tr><th>项目</th><th>说明</th></tr></thead><tbody><tr><td><strong>版本兼容</strong></td><td>sklearn 1.4 后 <code>n_init</code> 默认改为 <code>&#39;auto&#39;</code>，显式设置可避免警告</td></tr><tr><td><strong>数据标准化</strong></td><td>特征量纲差异大时先标准化（如 StandardScaler），避免某些特征主导距离</td></tr><tr><td><strong>随机种子</strong></td><td>设置 <code>random_state</code> 保证实验可复现</td></tr><tr><td><strong>初始质心</strong></td><td>优先使用 <code>init=&#39;k-means++&#39;</code>，比随机初始化更稳定</td></tr></tbody></table><hr><h2 id="三、知识小结" tabindex="-1">三、知识小结 <a class="header-anchor" href="#三、知识小结" aria-label="Permalink to &quot;三、知识小结&quot;">​</a></h2><table tabindex="0"><thead><tr><th>知识点</th><th>核心内容</th><th>易混淆点 / 关键细节</th><th>难度</th></tr></thead><tbody><tr><td><strong>K-Means 原理</strong></td><td>迭代优化聚类中心，按距离将样本分配到最近簇</td><td>需<strong>预先指定</strong>簇数；初始中心对结果影响大</td><td>⭐⭐⭐⭐</td></tr><tr><td><strong>聚类评估</strong></td><td>可用 Calinski-Harabasz 指数、轮廓系数等；CH/轮廓越大越好</td><td>无监督指标与分类准确率等监督指标区分开</td><td>⭐⭐⭐</td></tr><tr><td><strong>数据与标准化</strong></td><td>通过 <code>cluster_std</code> 控制生成数据离散程度；实际数据常需标准化</td><td>标准差与分布形状、聚类边界清晰度的关系</td><td>⭐⭐</td></tr><tr><td><strong>随机种子</strong></td><td><code>random_state</code> 固定后每次运行结果一致</td><td>不设置则每次可能不同，影响复现与调参</td><td>⭐</td></tr><tr><td><strong>聚类可视化</strong></td><td>用 matplotlib 按 <code>y_pred</code> 着色展示不同簇</td><td>高维时需降维或选两维再画图</td><td>⭐⭐</td></tr><tr><td><strong>无监督特点</strong></td><td>只需特征 <code>x</code>，用 <code>fit_predict(x)</code> 一步得到标签</td><td>与监督学习的 <code>fit(x,y)</code> + <code>predict(x)</code> 区分</td><td>⭐⭐⭐</td></tr><tr><td><strong>多维数据</strong></td><td><code>n_features</code> 控制生成数据维度；高维距离仍可用欧氏等</td><td>高维易出现“维度灾难”，可视化困难</td><td>⭐⭐⭐⭐</td></tr><tr><td><strong>参数调优</strong></td><td><code>n_init</code> 控制质心初始化次数；<code>n_clusters</code> 需人工或指标辅助选择</td><td>初始化次数与计算效率的权衡</td><td>⭐⭐⭐</td></tr></tbody></table><hr><p><em>文档已按“原理 → 数据 → 建模 → 评估 → 代码与注意点 → 知识小结”整理，便于复习与实现 K-Means 聚类。</em></p>`,62)]))}const c=i(l,[["render",e]]);export{E as __pageData,c as default};
