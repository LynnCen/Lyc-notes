import{_ as e,c as p,o as A,a8 as i}from"./chunks/framework.D9WC-p0B.js";const l=JSON.parse('{"title":"","description":"","frontmatter":{},"headers":[],"relativePath":"softExam/架构师/xx.md","filePath":"softExam/架构师/xx.md","lastUpdated":1762824279000}'),n={name:"softExam/架构师/xx.md"};function a(o,t,r,s,I,m){return A(),p("div",null,[...t[0]||(t[0]=[i("<p>以稿定AI+一体化架构实践</p><p>摘要 本文论述了我在2024年1月至2025年3月期间，发起了稿定设计AI+一体化重构项目，我作为了项目架构师与负责人，主要负责稿定设计国内主站、AI社区和海外Insmind一体化重构，主要解决原有单体架构下迭代缓慢、技术陈旧、跨站体验不一致的核心问题。为实现业务的快速迭代和技术的可持续演进，我采用“分层+微服务+事件驱动”的混合架构模式，我重点运用了领域驱动设计（DDD）进行服务边界划分，理清了模版、素材、AI编辑等核心领域，并通过API GateWay与BFF模式进行内外治理，为解决分布式下数据不一致问题，我采用了“事件发件箱+CDC”的事件驱动模式，保障了跨服务之间的最终一致性问题。整个架构以Kubernates进行容器化部署与编排，实现了弹性可伸缩与高可用，并通过CI/CD与可观测体系保证发布的敏捷与稳定。同时，AI能力通过Dify私有化与Agent工程化实现多模型编排与RAG增强，将AI能力贯穿“找素材、做设计、出成品、投分发、看效果”的端到端链路，让不会设计的人也能一步完成高质量创作。项目上线后，系统在性能与效率上取得了显著的提升：接口P95延迟、首屏时长、峰值QPS、导出成功率、SLA、推理成本与人效等关键指标取得显著改善，也为公司“AI+”战略的平台化落地奠定了坚实基础。 一、项目概述与我的职责 我置身与数字内容与营销高速增长的行业周期，看到非设计人群已经成为内容的主要生产里，以往的工具链设置了高门槛且协作链路冗长；跨团队、跨站点的品牌规范与体验难以保持一致；同时“海量模版检索、跨端适配与全球分发”的性能问题，与“生成式AI下在合规与成本约束下的落地”问题在同一套业务流程中叠加，直接影响转化率、导出率、口碑与增长；跨站间的技术不一致、技术陈旧与模型差异，形成了事实上“技术孤岛”，导致新功能无法跨站复用，迭代周期长。项目的核心目标，就是构建一个统一、高效、可拓展的平台化基座，以xxx架构作为核心驱动力，支撑未来3-5年业务发展。</p><p>在该项目中，我担任架构师与项目负责人，全面负责技术方案的制定与落地。我的职责贯穿始终。首先，在项目初期，我深入分析业务痛点，我把主干流程抽象为“模版检索-&gt;在线编辑 -&gt; AI生成/改图 -&gt; 导出分发”。海量模版与素材需要在显示字段、标签与向量特征上实现多维检索与相似度召回；在线编辑必须覆盖图/文/视频等形态，并提供无障碍的一键导出；AI侧提供文生图、图生图以及视频类等内容生成，也要提供抠图、扩图、消除与对话式作图等增强能力。导出与分发要通过对象储存与CDN服务跨区低时延抵达。在设计阶段，我主导技术选型与核心组件设计，特别是服务拆分策略、跨服务通信机制、数据一致性方案以及AI能力的编排集成。最后在实现与运维阶段，我协同前后端、算法与AI及SRE团队，推动敏捷开发与Devops实践，并建立了完善的CI/CD、灰度发布与可观测体系，确保架构的平稳过渡与持续演进。 总体架构设计 我采用“分层+微服务+事件驱动”的混合架构，以应对跨站一致性、服务耦合与AI长耗时任务的挑战。在分层设计上，我将系统划分为用户体验层、业务边界层和核心服务层。其中核心服务层是架构的主体，采用微服务架构方式。在服务的划分上，我运用领域驱动设计（DDD）进行治理，将服务拆分为认证授权、模版素材、在线编辑、资产网关、计费订单及AI编排等高内聚微服务，服务间采用gRPC通信，配合严格的API版本管理与契约测试，实现了服务的稳定演进。为解耦这些服务并保障数据一致性，我引入了事件驱动机制，采用事件发件箱+CDC模式将领域事件可靠发布至消息总校，由下游幂等消费，以处理所有长耗时任务并却带分布式事务。整个架构运行在以Kubernates为核心的基础设施智商，通过CI/CD实现灰度发布，并由OpenTelemetry三件套提供全链路可观测性，确保系统的透明与可控。</p><p>正文 AI能力分散与治理问题 当我深入调研AI接入现状时，发现问题比预想的严重。各业务线各自调用不同模型，没有统一容错，稳定性很差。国内必须用豆包等国产模型，海外可以用GPT，但缺乏智能路由，存在合规风险。生成内容质量波动大，缺乏评测标准，质量不可控。不管场景都用GPT-4这样的重模型，导致成本失控，月账单惊人。生成内容与品牌调性经常偏离，品牌一致性无法保障。</p><p>稳定性差：各业务线各自调用不同模型，没有统一容错 合规风险：国内必须使用豆包等国产模型，海外可食用GPT、但是缺乏智能路由 质量不可控：生成内容质量波动大，缺乏评测标准 成本失控：不管场景都使用GPT-4，月账单惊人 品牌不一致：生成内容与品牌调性偏离</p><p>解决</p><p>AI编排中枢：Dify私有化部署：</p><p>我首先建设了统一的AI编排层。选择Dify进行私有化部署，将其作为工作流与连接器层。我的设计思路是所有模型与工具都以JSON Schema统一注册，任何能力都以函数调用方式接入，形成低耦合、可替换、可治理的底座。这样做的核心价值是让AI从点状能力变为平台能力。 Agent工程化体系：</p><ul><li>智能路由策略：国内优先使用豆包，国外使用GPT、Gemini</li><li>提示词工程化管理：提示词版本化、标签化管理，结合离线测评集与在线A/B测试，建立promptOps闭环，提升质量稳定性。</li><li>故障降级机制：一级降级：切换到备用模型，二级降级：回退到规则化模版，三级降级：局部重绘，保留用户已有工作。 RAG增强：解决品牌一致性问题 向量知识库建设：选用PGBerctor/Milvus进行品牌设计规范、高频文案语料库、优质模版库、行业术语等 Embedding流水线：统一文本、图像的语义空间、定期更新向量索引 检索增强策略：用户输入-》Embedding-》向量召回，重排序，注入Prompt上下文，模型生成 评测与成本治理闭关（完整的AI质量与成本体系） PromptOps监控看板：性能（token数、时延、QPS)，质量(错误率、拒答率、人工验收得分)，必要时切换至重模型，峰值时段按性价比动态调度。</li></ul><p>成本优化实践：GPU/CUDA优化（模型量化）、批处理推理，任务编排优化。</p><p>我首先建设了统一的AI编排层。选择Dify进行私有化部署，将其作为工作流与连接器层。我的设计思路是所有模型与工具都以JSON Schema统一注册，任何能力都以函数调用方式接入，形成低耦合、可替换、可治理的底座。这样做的核心价值是让AI从点状能力变为平台能力。 在Dify之上，我建设了Agent工程化体系。智能路由策略方面，我设计了这样的逻辑：如果用户在国内，优先调用豆包、文心一言等国产模型；如果用户在海外，优先调用GPT-4、Gemini等国际模型；当质量偏离阈值或成本超标时，按策略切换模型或回退到规则化模板。这样做的效果是合规风险降为零，成本降低了35%。 提示词工程化管理方面，我实施了版本化、标签化管理，结合离线评测集与在线A/B测试，建立PromptOps闭环。这让质量稳定性提升了40%。 故障降级机制方面，我设计了三级降级策略。一级降级是切换到备用模型，二级降级是回退到规则化模板，三级降级是局部重绘并保留用户已有工作。这让可用性从95%提升至99.5%以上。 我发现纯大模型无法保证品牌一致性，于是引入了RAG技术。向量知识库建设方面，我选择了PGVector或Milvus作为技术方案。我的数据策略是将品牌设计规范包括色彩、字体、间距，高转化文案语料库，优质模板库也就是已验证效果好的模板，以及行业术语词典都纳入知识库。建设了Embedding流水线，统一文本、图像的语义空间，并定期更新向量索引。 检索增强策略的实现流程是：用户输入先进行Embedding，然后向量召回Top-K，再进行重排序结合业务规则，将结果注入Prompt上下文，最后由模型生成。这让品牌一致性从60%提升至85%以上。 我建立了完整的AI质量与成本治理体系。构建了PromptOps监控看板，采集的指标包括性能方面的token数、时延、QPS，质量方面的错误率、拒答率、人工验收得分，以及成本方面的每次调用成本和月度账单。优化策略是优先使用轻模型加工具链比如GPT-3.5加Function Calling，必要时才切换重模型比如GPT-4，峰值时段按性价比动态调度。</p><p>结论与展望</p>",12)])])}const d=e(n,[["render",a]]);export{l as __pageData,d as default};
