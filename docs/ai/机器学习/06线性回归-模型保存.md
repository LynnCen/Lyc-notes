一、线性回归模型预测学生成绩 
1. 分析 

模型持久化概念：当训练数据量达到几百万甚至几千万时，每次预测都重新训练模型是不现实的，因此需要将训练好的模型参数保存下来，这个过程称为模型持久化。
实现方法：通过joblib库的dump和load方法实现，保存为二进制文件格式。
2. 模型保存和模型重新加载 

保存步骤：
依赖库：需要先导入joblib库
保存语法：joblib.dump(estimator, './model/mylrmodel01.bin')，第一个参数是训练好的模型对象，第二个参数是保存路径
路径规范：建议保存在专门的model文件夹下，文件名以.bin结尾
加载步骤：
加载语法：myestimator2 = joblib.load('./model/mylrmodel01.bin')
使用方式：加载后的模型对象可以直接调用predict方法进行预测
完整流程：模型训练→评估→保存→加载→预测，这是标准的机器学习项目构建流程
二、回归任务 
1. 代码  

数据准备：
输入特征x：如[[80,86],[82,80],[85,78],[90,90],[86,82]]
输出标签y：如[84.2,80.6,80.1,90,83.2]
模型训练：
实例化：regression = LinearRegression()
训练：regression.fit(x, y)
查看参数：regression.coef_和regression.intercept_
2. 分析 

joblib.dump参数：
value参数：需要保存的Python对象（训练好的模型）
filename参数：保存路径，支持压缩格式如'.z'、'.gz'等
实际应用技巧：
保存路径可通过右键文件获取绝对路径
加载后的模型对象建议重新命名（如estimator1）以避免混淆
预测时输入格式需保持与训练时一致（如列表形式[90,80]）
三、知识小结
知识点核心内容考试重点/易混淆点难度系数模型训练与预测讲解如何训练模型并进行预测，使用8个样本示例训练数据量与实际应用的关系（如千万级数据处理）⭐⭐模型持久化（保存与加载）通过joblib实现模型保存（dump）和加载（load）文件名路径处理、二进制文件格式区分⭐⭐⭐模型部署流程完整流程：训练→评估→保存→加载→预测加载后需通过predict方法执行预测⭐⭐代码实操要点演示保存路径设置（如./model/my_model22）路径动态获取（右键选择路径）⭐⭐⭐预测结果验证对比训练时与加载后的预测结果一致性数据输入格式（列表形式如[90,80,66]）⭐⭐


## 特征预处理

### 归一化

一、特征预处理 
1. 为什么做归一化和标准化 
量纲问题：当特征的单位或大小相差较大时，数值较大的特征会主导模型训练结果
方差影响：某特征的方差相比其他特征大出几个数量级时，会导致模型无法有效学习其他特征
实例分析：以男子健康数据为例，身高(1.7m)、体重(67kg)、视力(1.5)三个特征单位不同，体重数值明显大于其他特征，容易导致模型偏差
1）例题:男子健康状况分析 

特征分析：表格显示身高(米)、体重(kg)、视力(0.2-2.0)三个特征单位差异明显
影响机制：体重数值范围(60-90)远大于视力(0.6-1.8)，模型会误认为数值大的特征更重要
解决方案：通过归一化/标准化消除量纲影响，使各特征具有可比性
2. 归一化 

核心公式：将数据映射到[0,1]区间
区间调整：可将数据调整到任意[mi,mx]区间
计算步骤：
计算每列最小值和最大值
使用第一个公式得到[0,1]区间的值
如需其他区间，使用第二个公式进行线性变换
实例演算：以数值90为例，当min=60，max=90时，(90-60)/(90-60)=1；数值60则转换为0
3. 数据归一化API 

导入路径：from sklearn.preprocessing import MinMaxScaler
关键参数：
feature_range：指定缩放范围，默认为(0,1)
核心方法：
fit_transform(X)：同时计算并应用变换
使用流程：
实例化转换器：transformer = MinMaxScaler()
拟合转换数据：data = transformer.fit_transform(X)
4. 应用案例 
1）例题:特征预处理并预测

代码结构：
准备数据：二维数组形式，每行一个样本，每列一个特征
实例化转换器：默认使用[0,1]区间
转换数据：调用fit_transform方法
输出结果：打印归一化后的数据
结果验证：原始数据[[90,2,10,40],[60,4,15,45],[75,3,13,46]]转换后符合预期
2）例题:特征预处理 

开发技巧：
使用IDE自动补全功能快速导入类
通过查看源码(Ctrl+点击)了解参数详情
结果与手工计算一致，验证了API的正确性
注意事项：
输入数据必须是二维数组形式
默认情况下不修改feature_range参数
fit_transform方法会同时计算统计量并应用转换
二、知识小结
知识点核心内容考试重点/易混淆点难度系数特征预处理的目的解决特征单位和量纲差异导致模型训练偏差的问题，通过归一化/标准化使不同特征具有可比性量纲问题（如身高cm vs 体重kg）、方差差异导致模型偏向大数值特征⭐⭐归一化原理线性映射到指定区间（默认[0,1]）：公式为 (x-min)/(max-min)，扩展公式支持自定义区间（如[1,10]）区间缩放计算（需掌握公式推导）、默认区间与自定义区间的转换逻辑⭐⭐⭐归一化API（MinMaxScaler）sklearn.preprocessing.MinMaxScaler 的 feature_range 参数控制目标区间，fit_transform 方法执行计算与转换参数默认值（feature_range=(0,1)）、fit_transform的拆分意义（fit计算统计量+transform应用转换）⭐⭐归一化实例演示通过身高/体重/视力数据示例，展示原始值→[0,1]映射过程（如90→1.0，60→0.0）二维数据输入格式（必须为矩阵）、边界值处理（最大值/最小值映射结果）⭐归一化局限性对异常值敏感（极端值影响min/max）、仅适用于线性分布场景与标准化的区别（标准化基于方差/均值，适合存在异常值的情况）⭐⭐

### 标准化

一、特征预处理 
1. 数据标准化

核心概念：将原始数据转换为均值为0，标准差为1的标准正态分布数据
数学表达：，其中为均值，为标准差
希腊字符解析：
（缪）：表示特征均值，决定分布中心位置
（西格玛）：表示标准差，反映数据离散程度
：表示方差，标准差平方
工程应用要点：
面试中需准确发音希腊字符（缪/mjuː/，西格玛/'sɪɡmə/）
标准化后数据满足：68%在，95%在，99.7%在
1）代码演示 

API使用：
from sklearn.preprocessing import StandardScaler
实例化：transformer = StandardScaler()
转换数据：data = transformer.fit_transform(data)
关键属性：
transformer.mean_：获取各列均值
transformer.var_：获取各列方差（注意不是标准差）
与归一化区别：
归一化使用MinMaxScaler，受异常值影响大
标准化使用StandardScaler，对异常值鲁棒性强
2. 规律总结 

核心区别：
归一化：基于最大值最小值，公式
异常值敏感，适合小数据场景
默认缩放到[0,1]区间
标准化：基于均值标准差
对异常值鲁棒性强，适合大数据场景
结果符合正态分布特性
记忆口诀：
"归一看极差，标准看分布"
"小数据用归一，大数据用标准"
1）例题:填空归纳 

题目解析：
第一空：归一化公式中和易受异常值影响，体现鲁棒性差
第二空：标准化在大样本量时对异常值不敏感
答案：
最大值最小值
样本数量大
易错点：
混淆方差(var_)和标准差属性
误认为标准化后数据范围在[0,1]（实际无固定范围）
二、知识小结
知识点核心内容考试重点/易混淆点难度系数标准化方法将数据转化为均值为0、方差为1的正态分布，公式：(x - μ)/σ（μ为均值，σ为标准差）μ与σ的希腊字符发音（μ:缪，σ:西格玛）
方差与标准差关系：σ²=方差，σ=标准差⭐⭐归一化方法将数据缩放到固定范围（默认0-1），公式：(x - min)/(max - min)异常值影响：依赖最大值/最小值，鲁棒性较差
API：MinMaxScaler(feature_range=(0,1))⭐⭐正态分布特性3σ法则：
- 68%数据在[μ-σ, μ+σ]
- 95%在[μ-2σ, μ+2σ]
- 99.7%在[μ-3σ, μ+3σ]参数含义：μ决定分布位置，σ决定离散程度
标准正态分布：μ=0, σ=1⭐⭐⭐API对比标准化：StandardScaler()（计算均值/方差）
归一化：MinMaxScaler()（计算极差）适用场景：
- 标准化：大数据/存在异常值
- 归一化：小数据/鲁棒性要求低⭐⭐工程术语鲁棒性=泛化性；方差=var；标准差=std面试注意：希腊字符发音（如μ读作“缪”）需准确⭐

