# 机器学习算法分类

> 本章介绍机器学习的四大学习范式：监督学习、无监督学习、半监督学习、强化学习

---

## 一、四大学习范式概览

```
┌────────────────────────────────────────────────────────────────┐
│                    机器学习算法分类                              │
├────────────────┬────────────────┬────────────────┬─────────────┤
│   监督学习      │   无监督学习    │   半监督学习    │   强化学习   │
│  Supervised    │  Unsupervised  │ Semi-Supervised│ Reinforcement│
├────────────────┼────────────────┼────────────────┼─────────────┤
│  ✅ 有标签     │  ❌ 无标签      │  🔄 部分标签    │  🎮 交互反馈 │
│  分类/回归     │  聚类          │  标签传播       │  策略优化    │
└────────────────┴────────────────┴────────────────┴─────────────┘
```

---

## 二、监督学习（Supervised Learning）

### 2.1 核心特征

::: tip 定义
**监督学习**：输入数据由特征值（X）和目标值（y）组成，训练数据必须带有标签。
:::

**关键要素：**
- ✅ 有标签数据
- ✅ 有反馈机制（模型知道预测对错）
- ✅ 需要"监督者"提供明确的标签指导

### 2.2 两大子类

```
监督学习
    │
    ├── 📈 回归 (Regression)
    │       └── 目标值为连续值
    │       └── 例：房价预测、温度预测
    │
    └── 🏷️ 分类 (Classification)
            └── 目标值为离散值
            └── 例：猫狗分类、垃圾邮件识别
```

| 类型 | 目标值 | 典型任务 | 评估指标 |
|------|--------|----------|----------|
| **回归** | 连续值（如 15000, 18.5） | 房价预测、销量预测 | MSE, RMSE, MAE |
| **分类** | 离散值（如 猫/狗, 0/1） | 图像分类、情感分析 | 准确率、F1-Score |

### 2.3 典型示例：电影分类

| 电影 | 搞笑镜头 | 拥抱镜头 | 打斗镜头 | 类型（标签）|
|------|----------|----------|----------|-------------|
| 功夫熊猫 | 45 | 12 | 30 | 喜剧片 |
| 泰坦尼克 | 5 | 50 | 8 | 爱情片 |
| 叶问 | 10 | 8 | 80 | 动作片 |

::: info 易混淆点
区分分类与回归的依据是**目标值类型**，而非特征！
:::

---

## 三、无监督学习（Unsupervised Learning）

### 3.1 核心特征

::: tip 定义
**无监督学习**：输入数据无任何标签，通过样本间相似性进行分组，发现数据内部结构。
:::

**关键要素：**
- ❌ 无标签数据
- ❌ 无反馈机制
- ✅ 基于相似性自动聚类

### 3.2 聚类示意

```
原始数据（无标签）          聚类后
    ●  ▲  ■                 ┌─────────┐
    ●  ▲  ■     ────►       │ ● ● ●  │ 类别 A
    ●  ▲  ■                 ├─────────┤
    ●  ▲  ■                 │ ▲ ▲ ▲  │ 类别 B
                            ├─────────┤
                            │ ■ ■ ■  │ 类别 C
                            └─────────┘
```

### 3.3 特点

| 特点 | 说明 |
|------|------|
| 分类自由 | 可根据需求灵活确定类别数量 |
| 无标准答案 | 聚类结果依赖主观定义 |
| 发现结构 | 揭示数据内在规律 |

::: details 💡 典型应用
- 用户分群（电商用户画像）
- 图像分割
- 异常检测
- 新闻话题聚类
:::

---

## 四、半监督学习（Semi-Supervised Learning）

### 4.1 核心特征

::: tip 定义
**半监督学习**：结合少量标注数据和大量未标注数据进行训练。
:::

### 4.2 工作流程

```
┌─────────────────────────────────────────────────────────────┐
│                     半监督学习流程                           │
└─────────────────────────────────────────────────────────────┘
         │
         ▼
┌─────────────────┐    ┌─────────────────┐
│ 1️⃣ 少量标注数据  │ →  │ 2️⃣ 训练初始模型  │
│   (1万条)        │    │                 │
└─────────────────┘    └────────┬────────┘
                                │
                                ▼
┌─────────────────┐    ┌─────────────────┐
│ 4️⃣ 人工校正结果  │ ←  │ 3️⃣ 预测未标注数据 │
│   (修正错误)     │    │   (99万条)       │
└─────────────────┘    └─────────────────┘
```

### 4.3 核心优势

| 优势 | 说明 |
|------|------|
| 💰 降低成本 | 大幅减少人工标注工作量 |
| ⚡ 提高效率 | 用少量标注数据撬动大量数据 |
| 📊 适用场景 | 标注成本高但数据量大的任务 |

::: info 典型应用
数据标注领域：处理百万级数据集时，先用 1 万标注数据训练模型，再预测剩余 99 万数据。
:::

---

## 五、强化学习（Reinforcement Learning）

### 5.1 核心特征

::: tip 定义
**强化学习**：智能体通过与环境交互，根据奖励信号优化决策策略。
:::

### 5.2 四大核心要素

```
        ┌─────────────────────────────────────┐
        │           🌍 环境 (Environment)      │
        └─────────────────────────────────────┘
                    ▲           │
          State     │           │  Reward
          (状态)    │           │  (奖励)
                    │           ▼
        ┌─────────────────────────────────────┐
        │          🤖 智能体 (Agent)           │
        │                                     │
        │         选择 Action (行动)           │
        └─────────────────────────────────────┘
```

| 要素 | 英文 | 说明 |
|------|------|------|
| 🤖 **智能体** | Agent | 执行决策的主体 |
| 🌍 **状态** | State | 当前环境状况 |
| 🎯 **行动** | Action | 可执行的操作 |
| 🏆 **奖励** | Reward | 行动后的反馈 |

### 5.3 学习机制

**核心目标：** 通过**奖励最大化**驱动智能体优化策略

::: details 💡 生活示例
**儿童学走路：**
- 智能体：儿童
- 状态：当前姿势、位置
- 行动：迈步、保持平衡
- 奖励：成功走一步 → 巧克力 🍫
:::

### 5.4 典型案例

| 案例 | 智能体 | 奖励机制 |
|------|--------|----------|
| AlphaGo | 棋手程序 | 胜利 +1，失败 -1 |
| 无人驾驶 | 自动驾驶系统 | 安全行驶奖励，碰撞惩罚 |
| 游戏 NPC | 虚拟角色 | 完成任务奖励 |

::: warning 特点区分
强化学习能**实时**根据环境状态调整策略，区别于静态的历史数据学习。
:::

---

## 六、四大范式对比

| 维度 | 监督学习 | 无监督学习 | 半监督学习 | 强化学习 |
|------|----------|------------|------------|----------|
| **标签** | ✅ 全部有 | ❌ 全部无 | 🔄 部分有 | 🎮 动态奖励 |
| **反馈** | 即时反馈 | 无反馈 | 部分反馈 | 延迟反馈 |
| **目标** | 预测标签 | 发现结构 | 标签传播 | 策略优化 |
| **典型任务** | 分类、回归 | 聚类 | 数据标注 | 决策控制 |
| **典型案例** | 图像分类 | 用户分群 | 大规模标注 | AlphaGo |

---

## 七、知识小结

| 知识点 | 核心内容 | 考试重点/易混淆点 | 难度 |
|--------|----------|-------------------|------|
| 算法分类 | 四大类：监督、无监督、半监督、强化 | 区分标准：目标值是否存在及类型 | ⭐⭐ |
| 监督学习 | 有标签，分为回归（连续）和分类（离散） | 分类与回归的区分依据是目标值，而非特征 | ⭐⭐⭐ |
| 无监督学习 | 无标签，依赖样本相似度聚类 | 聚类结果无标准答案，依赖主观定义 | ⭐⭐ |
| 半监督学习 | 混合标记与未标记数据 | 优势：降低标注成本，提升效率 | ⭐⭐⭐⭐ |
| 强化学习 | 四要素：Agent、State、Action、Reward | 核心：实时交互与动态奖励反馈 | ⭐⭐⭐⭐⭐ |
| 面试逻辑 | 分类框架 → 每类定义 → 子类 → 示例 | 重点：层次清晰，结合实例 | ⭐⭐⭐ |

---

## 八、面试高频问题

::: tip 💬 常见面试题
**Q: 请介绍机器学习算法的主要分类及其特点？**

**A:** 机器学习算法主要分为四类：

1. **监督学习**：有标签数据，分为回归（目标值连续，如房价预测）和分类（目标值离散，如猫狗分类）

2. **无监督学习**：无标签数据，通过相似性进行聚类，如用户分群

3. **半监督学习**：部分有标签，常用于大规模数据标注场景，降低标注成本

4. **强化学习**：通过环境交互获得奖励反馈，优化决策策略。四要素为 Agent（智能体）、State（状态）、Action（行动）、Reward（奖励）。典型案例如 AlphaGo。
:::
